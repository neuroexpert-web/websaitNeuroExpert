from fastapi import FastAPI, APIRouter, HTTPException, Request
from fastapi.responses import Response
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
from pathlib import Path
from pydantic import BaseModel, Field
from typing import List, Optional
import uuid
from datetime import datetime
from emergentintegrations.llm.chat import LlmChat, UserMessage
import aiohttp
from config.loader import config
from utils.intent_checker import intent_checker
from memory.smart_context import smart_context
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration
from sentry_sdk.integrations.starlette import StarletteIntegration
from sentry_sdk.integrations.logging import LoggingIntegration
from sentry_sdk.integrations.asyncio import AsyncioIntegration
from sentry_sdk.integrations.opentelemetry import SentrySpanProcessor
from sentry_sdk import configure_scope
from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
from opentelemetry import trace
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.aiohttp_client import AioHttpClientInstrumentor
from opentelemetry.instrumentation.pymongo import PymongoInstrumentor
from contextlib import asynccontextmanager
import time

ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# MongoDB connection
mongo_url = os.environ.get('MONGO_URL')
db_name = os.environ.get('DB_NAME')

if not mongo_url or not db_name:
    raise RuntimeError("FATAL: MONGO_URL and DB_NAME must be set in environment variables")

client = AsyncIOMotorClient(mongo_url)
db = client[db_name]

# Environment variables
EMERGENT_LLM_KEY = os.environ.get('EMERGENT_LLM_KEY')
TELEGRAM_BOT_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID')
CLIENT_ORIGIN_URL = os.environ.get('CLIENT_ORIGIN_URL', 'http://localhost:3000')
SENTRY_DSN_BACKEND = os.environ.get('SENTRY_DSN_BACKEND')
SENTRY_ENABLED = os.environ.get('SENTRY_ENABLED', 'false').lower() in {'1', 'true', 'yes', 'on'}
SENTRY_ENVIRONMENT = os.environ.get('SENTRY_ENVIRONMENT', os.environ.get('APP_ENV', 'development'))
SENTRY_RELEASE = os.environ.get('SENTRY_RELEASE') or os.environ.get('GIT_COMMIT_SHA') or 'unknown'
SENTRY_TRACES_SAMPLE_RATE = os.environ.get('SENTRY_TRACES_SAMPLE_RATE', '0.2')
SENTRY_PROFILES_SAMPLE_RATE = os.environ.get('SENTRY_PROFILES_SAMPLE_RATE', '0.0')
SERVICE_NAME = os.environ.get('SERVICE_NAME', 'neuroexpert-backend')

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def _filter_pii(event, hint=None):
    """Remove PII from events before sending to Sentry."""
    request_data = event.get('request')
    if request_data:
        for key in ('headers', 'cookies', 'data'):
            if key in request_data:
                request_data[key] = '[FILTERED]'

    user_data = event.get('user')
    if user_data:
        event['user'] = {k: user_data[k] for k in ('id', 'username') if k in user_data}

    extra_data = event.get('extra')
    if extra_data:
        for key in list(extra_data.keys()):
            if any(token in key.lower() for token in ('email', 'phone', 'contact', 'name')):
                extra_data[key] = '[FILTERED]'

    return event


def _coerce_float(value: str, fallback: float, label: str) -> float:
    try:
        return float(value)
    except (TypeError, ValueError):
        logger.warning("Invalid value for %s=%s. Falling back to %s", label, value, fallback)
        return fallback


# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
# Sentry & OpenTelemetry initialization
# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
traces_sample_rate = _coerce_float(SENTRY_TRACES_SAMPLE_RATE, 0.2, 'SENTRY_TRACES_SAMPLE_RATE')
profiles_sample_rate = _coerce_float(SENTRY_PROFILES_SAMPLE_RATE, 0.0, 'SENTRY_PROFILES_SAMPLE_RATE')
SENTRY_ACTIVE = bool(SENTRY_DSN_BACKEND) and SENTRY_ENABLED and SENTRY_ENVIRONMENT != 'development'

if SENTRY_ACTIVE:
    sentry_sdk.init(
        dsn=SENTRY_DSN_BACKEND,
        environment=SENTRY_ENVIRONMENT,
        release=SENTRY_RELEASE,
        integrations=[
            FastApiIntegration(transaction_style="endpoint"),
            StarletteIntegration(transaction_style="endpoint"),
            LoggingIntegration(level=logging.INFO, event_level=logging.ERROR),
            AsyncioIntegration(),
        ],
        traces_sample_rate=traces_sample_rate,
        profiles_sample_rate=profiles_sample_rate,
        send_default_pii=False,
        before_send=_filter_pii,
    )
    with configure_scope() as scope:
        scope.set_tag('service', SERVICE_NAME)
        scope.set_tag('deployment', SENTRY_ENVIRONMENT)
    logger.info("‚úÖ Sentry initialized: %s [%s]", SENTRY_ENVIRONMENT, SENTRY_RELEASE)
else:
    logger.info(
        "‚ö†Ô∏è  Sentry disabled (environment=%s, enabled=%s, dsn=%s)",
        SENTRY_ENVIRONMENT,
        SENTRY_ENABLED,
        bool(SENTRY_DSN_BACKEND),
    )

# OpenTelemetry setup with Sentry integration
resource = Resource.create({
    "service.name": SERVICE_NAME,
    "service.version": SENTRY_RELEASE,
    "deployment.environment": SENTRY_ENVIRONMENT,
})
tracer_provider = TracerProvider(resource=resource)
trace.set_tracer_provider(tracer_provider)
tracer = trace.get_tracer("neuroexpert.backend")

if SENTRY_ACTIVE:
    tracer_provider.add_span_processor(SentrySpanProcessor())

# Instrument external libraries for tracing
AioHttpClientInstrumentor().instrument()
PymongoInstrumentor().instrument()

# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
# Prometheus Metrics
# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
REQUEST_IN_PROGRESS = Gauge(
    "neuroexpert_backend_requests_in_progress",
    "Number of HTTP requests currently processed",
    ("method", "path"),
)

REQUEST_COUNT = Counter(
    "neuroexpert_backend_requests_total",
    "Total HTTP requests processed",
    ("method", "path", "status"),
)

REQUEST_LATENCY = Histogram(
    "neuroexpert_backend_request_duration_seconds",
    "HTTP request duration in seconds",
    ("method", "path"),
    buckets=(0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0),
)

ERROR_COUNT = Counter(
    "neuroexpert_backend_error_responses_total",
    "Total HTTP error responses by class",
    ("method", "path", "status_class"),
)

EXTERNAL_CALL_LATENCY = Histogram(
    "neuroexpert_backend_external_call_duration_seconds",
    "Duration of external service calls",
    ("service",),
    buckets=(0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0),
)

EXTERNAL_CALL_COUNT = Counter(
    "neuroexpert_backend_external_calls_total",
    "Total external service calls grouped by outcome",
    ("service", "outcome"),
)

DB_OPERATION_LATENCY = Histogram(
    "neuroexpert_backend_db_operation_duration_seconds",
    "Duration of MongoDB operations",
    ("collection", "operation"),
    buckets=(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 2.0),
)

DB_OPERATION_COUNT = Counter(
    "neuroexpert_backend_db_operations_total",
    "Total MongoDB operations grouped by outcome",
    ("collection", "operation", "outcome"),
)


@asynccontextmanager
async def observe_external_call(service_name: str):
    start = time.perf_counter()
    outcome = "success"
    try:
        yield
    except Exception:
        outcome = "error"
        raise
    finally:
        duration = time.perf_counter() - start
        EXTERNAL_CALL_LATENCY.labels(service=service_name).observe(duration)
        EXTERNAL_CALL_COUNT.labels(service=service_name, outcome=outcome).inc()


@asynccontextmanager
async def observe_db_operation(collection: str, operation: str):
    start = time.perf_counter()
    outcome = "success"
    try:
        yield
    except Exception:
        outcome = "error"
        raise
    finally:
        duration = time.perf_counter() - start
        DB_OPERATION_LATENCY.labels(collection=collection, operation=operation).observe(duration)
        DB_OPERATION_COUNT.labels(collection=collection, operation=operation, outcome=outcome).inc()


# Lifespan context manager for startup/shutdown
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("üöÄ Starting NeuroExpert Backend API")
    # Instrument FastAPI after creation
    FastAPIInstrumentor.instrument_app(app)
    yield
    # Shutdown
    logger.info("üëã Shutting down NeuroExpert Backend API")
    client.close()

# Create the main app
app = FastAPI(lifespan=lifespan)

# Create a router with the /api prefix
api_router = APIRouter(prefix="/api")


# Models
class ContactForm(BaseModel):
    name: str
    contact: str
    service: str
    message: Optional[str] = ""

class ChatMessage(BaseModel):
    session_id: str
    message: str
    model: Optional[str] = "claude-sonnet"  # claude-sonnet, gpt-4o, gemini-pro
    user_data: Optional[dict] = None

class ChatResponse(BaseModel):
    response: str
    session_id: str


# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
# Metrics Middleware
# ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    """Record Prometheus metrics for all requests."""
    start_time = time.perf_counter()
    method = request.method
    path = request.url.path
    
    # Skip metrics endpoint itself
    if path == "/metrics":
        return await call_next(request)
    
    # Normalize endpoint for metrics (remove IDs)
    endpoint = path
    for route in app.routes:
        match = route.matches(request.scope)
        if match[0]:
            endpoint = route.path
            break
    
    REQUEST_IN_PROGRESS.labels(method=method, path=endpoint).inc()
    status = 500
    try:
        response = await call_next(request)
        status = response.status_code
        return response
    except Exception as e:
        logger.exception("Unhandled exception in request: %s", e)
        sentry_sdk.capture_exception(e)
        raise
    finally:
        duration = time.time() - start_time
        REQUEST_IN_PROGRESS.labels(method=method, path=endpoint).dec()
        
        # Record metrics
        REQUEST_COUNT.labels(method=method, path=endpoint, status=status).inc()
        REQUEST_LATENCY.labels(method=method, path=endpoint).observe(duration)
        
        if status >= 400:
            status_class = f"{status // 100}xx"
            ERROR_COUNT.labels(method=method, path=endpoint, status_class=status_class).inc()
            if status >= 500:
                logger.error("5xx error: %s %s -> %d (%.3fs)", method, path, status, duration)

# Telegram notification
async def send_telegram_notification(message: str):
    """Send notification to Telegram bot"""
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        logger.warning("Telegram not configured")
        return
            
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    async with observe_external_call("telegram"):
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json={
                "chat_id": TELEGRAM_CHAT_ID,
                "text": message,
                "parse_mode": "HTML"
            }) as response:
                if response.status == 200:
                    logger.info("‚úÖ Telegram notification sent successfully")
                else:
                    text = await response.text()
                    logger.error(f"Telegram notification failed! Status: {response.status}, Response: {text}")
                    raise Exception(f"Telegram API error: {response.status}")


# Routes
@app.get("/metrics")
async def metrics():
    return Response(content=generate_latest(), media_type=CONTENT_TYPE_LATEST)

@api_router.get("/")
async def root():
    return {"message": "NeuroExpert API"}

@api_router.post("/contact")
async def submit_contact_form(form_data: ContactForm):
    """Handle contact form submission"""
    try:
        form_dict = form_data.dict()
        form_dict['id'] = str(uuid.uuid4())
        form_dict['timestamp'] = datetime.utcnow()
        form_dict['status'] = 'new'
        
        async with observe_db_operation('contact_forms', 'insert_one'):
            await db.contact_forms.insert_one(form_dict)
        
        telegram_message = f"""
<b>üéØ –ù–æ–≤–∞—è –∑–∞—è–≤–∫–∞ NeuroExpert!</b>

<b>–ò–º—è:</b> {form_data.name}
<b>–ö–æ–Ω—Ç–∞–∫—Ç:</b> {form_data.contact}
<b>–£—Å–ª—É–≥–∞:</b> {form_data.service}
<b>–°–æ–æ–±—â–µ–Ω–∏–µ:</b> {form_data.message or '–ù–µ —É–∫–∞–∑–∞–Ω–æ'}
"""
        
        try:
            await send_telegram_notification(telegram_message)
        except Exception as notify_error:
            logger.error("Telegram notification failed: %s", notify_error)
            sentry_sdk.capture_exception(notify_error)
        
        logger.info(f"Contact form: {form_data.name} - {form_data.service}")
        
        return {
            "success": True,
            "message": "–°–ø–∞—Å–∏–±–æ! –ú—ã —Å–≤—è–∂–µ–º—Å—è —Å –≤–∞–º–∏ –≤ —Ç–µ—á–µ–Ω–∏–µ 15 –º–∏–Ω—É—Ç"
        }
    except Exception as e:
        logger.error(f"Contact form error: {str(e)}")
        sentry_sdk.capture_exception(e)
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞—è–≤–∫–∏")


@api_router.post("/chat", response_model=ChatResponse)
async def chat_with_ai(chat_request: ChatMessage):
    """AI chat with multiple model support"""
    # Check for relevance
    if not intent_checker.is_relevant(chat_request.message):
        return ChatResponse(
            response=config.data['fallback_responses']['irrelevant'],
            session_id=chat_request.session_id
        )

    try:
        # Enhanced system prompt with better context handling
        system_prompt = f"""# IDENTITY & CORE ROLE

–í—ã ‚Äî **AI-–ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç {config.data['company']['name']}**, –ø–µ—Ä–≤–∞—è —Ç–æ—á–∫–∞ –∫–æ–Ω—Ç–∞–∫—Ç–∞ –∫–ª–∏–µ–Ω—Ç–∞ —Å —ç–∫–æ—Å–∏—Å—Ç–µ–º–æ–π digital-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏. 

**–í–∞—à–∞ –ª–∏—á–Ω–æ—Å—Ç—å:**
- –≠–∫—Å–ø–µ—Ä—Ç –≤ digital-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å 10+ –ª–µ—Ç –æ–ø—ã—Ç–∞
- –ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç-–ø–∞—Ä—Ç–Ω–µ—Ä, –∞ –Ω–µ –ø—Ä–æ–¥–∞–≤–µ—Ü: —Å–Ω–∞—á–∞–ª–∞ –≥–ª—É–±–æ–∫–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞, –ø–æ—Ç–æ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
- –ì–æ–≤–æ—Ä–∏—Ç–µ –∂–∏–≤—ã–º, –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º, –∞–¥–∞–ø—Ç–∏—Ä—É—è—Å—å –∫ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫—É
- –î—Ä—É–∂–µ–ª—é–±–Ω—ã, —ç–º–ø–∞—Ç–∏—á–Ω—ã, –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã
- –í—Å–µ–≥–¥–∞ –ø–æ–º–Ω–∏—Ç–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –≤–∞–∂–Ω—ã–º –¥–µ—Ç–∞–ª—è–º
- –û—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –ø–æ–ª—å–∑—É –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞, –∞ –Ω–µ –Ω–∞ –ø—Ä–æ–¥–∞–∂—É

**–°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è:**
- –û—Ç–≤–µ—á–∞–π—Ç–µ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ (3-6 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π), –Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ
- –ó–∞–¥–∞–≤–∞–π—Ç–µ —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –ø—Ä–∞–∫—Ç–∏–∫–∏
- –û–±—ä—è—Å–Ω—è–π—Ç–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º
- –ë—É–¥—å—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã –≤ —Ü–∏—Ñ—Ä–∞—Ö –∏ —Å—Ä–æ–∫–∞—Ö
- –ü—Ä–æ—è–≤–ª—è–π—Ç–µ –∂–∏–≤–æ–π –∏–Ω—Ç–µ—Ä–µ—Å –∫ –ø—Ä–æ–±–ª–µ–º–µ –∫–ª–∏–µ–Ω—Ç–∞

## –ù–ê–®–ò –£–°–õ–£–ì–ò
{config.get_all_services_text()}

## –ö–û–ù–¢–ê–ö–¢–´
–¢–µ–ª–µ—Ñ–æ–Ω: {config.data['company']['phone']}
Email: {config.data['company']['email']}
–ó–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤: {config.data['company']['completed_projects']}

## –¢–ï–•–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –°–¢–ï–ö

**Frontend:** React.js/Next.js 15, Vue.js/Nuxt.js, TailwindCSS
**Backend:** Node.js, Python/FastAPI, Golang
**AI/ML:** Claude Sonnet 4, GPT-4o, Gemini Pro, LangChain
**–ë–î:** PostgreSQL, MongoDB, Redis, Vector DB
**–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:** SSL/TLS, WAF, Cloudflare Protection, GDPR/152-–§–ó compliance

## –ì–ê–†–ê–ù–¢–ò–ò

‚úÖ –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ä–æ–∫ –∏–ª–∏ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è 10 000‚ÇΩ
‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
‚úÖ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è
‚úÖ NDA –∏ –ø–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å
‚úÖ 30-90 –¥–Ω–µ–π –≥–∞—Ä–∞–Ω—Ç–∏–π–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏
‚úÖ Uptime 99.5-99.99% (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∞—Ä–∏—Ñ–∞)

## –ü–†–û–¶–ï–°–° –†–ê–ë–û–¢–´

1. **–ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è** (30 –º–∏–Ω) - —Ä–∞–∑–±–æ—Ä –∑–∞–¥–∞—á–∏, –ø–µ—Ä–≤–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
2. **–ê—É–¥–∏—Ç/–¢–ó** - –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑, –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ—à–µ–Ω–∏—è
3. **–î–∏–∑–∞–π–Ω** - –ø—Ä–æ—Ç–æ—Ç–∏–ø—ã, UX/UI (—Å –≤–∞—à–∏–º —É—á–∞—Å—Ç–∏–µ–º)
4. **–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞** - —Å–ø—Ä–∏–Ω—Ç—ã –ø–æ 1-2 –Ω–µ–¥–µ–ª–∏, —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –¥–µ–º–æ
5. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** - QA, –Ω–∞–≥—Ä—É–∑–æ—á–Ω—ã–µ —Ç–µ—Å—Ç—ã
6. **–ó–∞–ø—É—Å–∫** - –ø–æ—ç—Ç–∞–ø–Ω—ã–π deployment, –æ–±—É—á–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã
7. **–ü–æ–¥–¥–µ—Ä–∂–∫–∞** - –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è, —Ä–∞–∑–≤–∏—Ç–∏–µ

## –°–¢–†–ê–¢–ï–ì–ò–Ø –î–ò–ê–õ–û–ì–ê

**–ü—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏:**
1. –¢–µ–ø–ª–æ –ø–æ–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–π—Ç–µ –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ—Å—å
2. –ó–∞–¥–∞–π—Ç–µ 2-3 –æ—Ç–∫—Ä—ã—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –æ –∑–∞–¥–∞—á–µ –∫–ª–∏–µ–Ω—Ç–∞
3. –í—ã—Å–ª—É—à–∞–π—Ç–µ –∏ —Ä–µ–∑—é–º–∏—Ä—É–π—Ç–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
4. –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º
5. –î–∞–π—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–µ –∫–µ–π—Å—ã –∏–ª–∏ –ø—Ä–∏–º–µ—Ä—ã
6. –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ (–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è/–≤—Å—Ç—Ä–µ—á–∞/–∞—É–¥–∏—Ç)

**–í —Ö–æ–¥–µ –¥–∏–∞–ª–æ–≥–∞:**
- –í—Å–µ–≥–¥–∞ –ø–æ–º–Ω–∏—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞
- –û–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –¥–µ—Ç–∞–ª—è–º –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
- –°—Ç—Ä–æ–π—Ç–µ –ª–æ–≥–∏—á–µ—Å–∫—É—é —Ü–µ–ø–æ—á–∫—É –≤–æ–ø—Ä–æ—Å–æ–≤
- –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π—Ç–µ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ - —Ä–∞–∑–≤–∏–≤–∞–π—Ç–µ —Ç–µ–º—É
- –ë—É–¥—å—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã, –Ω–æ –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞–π—Ç–µ –¥–µ—Ç–∞–ª—è–º–∏

**–ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –≥–æ—Ç–æ–≤:**
- –ú—è–≥–∫–æ –≤–µ–¥–∏—Ç–µ –∫ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—é —Ñ–æ—Ä–º—ã –∫–æ–Ω—Ç–∞–∫—Ç–∞
- –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ (–∑–≤–æ–Ω–æ–∫, –≤—Å—Ç—Ä–µ—á—É, –∞—É–¥–∏—Ç)
- –ü–æ–¥—á–µ—Ä–∫–Ω–∏—Ç–µ —Ü–µ–Ω–Ω–æ—Å—Ç—å —Å–ª–µ–¥—É—é—â–µ–≥–æ —à–∞–≥–∞

**–ü—Ä–∏–º–µ—Ä—ã –≤–∞—à–µ–≥–æ —Ç–æ–Ω–∞:**
‚ùå "–ú—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º —É—Å–ª—É–≥–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏."
‚úÖ "–î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è, –∫–∞–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ –±—É–¥–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –∏–º–µ–Ω–Ω–æ –¥–ª—è –≤–∞—à–µ–π –∑–∞–¥–∞—á–∏. –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ - —á—Ç–æ —Å–µ–π—á–∞—Å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏ –∫–∞–∫–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–ª—É—á–∏—Ç—å?"

‚ùå "–°—Ç–æ–∏–º–æ—Å—Ç—å –æ—Ç 150 000 —Ä—É–±–ª–µ–π."
‚úÖ "–î–ª—è –≤–∞—à–µ–≥–æ —Å–ª—É—á–∞—è –ø–æ–¥–æ–π–¥–µ—Ç –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π —Å–∞–π—Ç. –°—Ç–æ–∏–º–æ—Å—Ç—å 150-300 —Ç—ã—Å—è—á, –Ω–æ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ —Å–Ω–∏–∂–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ª–∏–¥–∞ –Ω–∞ 40% —É–∂–µ —á–µ—Ä–µ–∑ 3 –º–µ—Å—è—Ü–∞. –ü–æ –Ω–∞—à–µ–º—É –æ–ø—ã—Ç—É, —Ç–∞–∫–æ–π –ø—Ä–æ–µ–∫—Ç –æ–∫—É–ø–∞–µ—Ç—Å—è –∑–∞ –ø–æ–ª–≥–æ–¥–∞."

–ë—É–¥—å—Ç–µ –∂–∏–≤—ã–º, –ø–æ–ª–µ–∑–Ω—ã–º —ç–∫—Å–ø–µ—Ä—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–∫—Ä–µ–Ω–Ω–µ —Ö–æ—á–µ—Ç –ø–æ–º–æ—á—å —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É –∫–ª–∏–µ–Ω—Ç–∞!"""

        # Model mapping (only working models)
        model_config = {
            "claude-sonnet": ("anthropic", "claude-3-7-sonnet-20250219"),
            "gpt-4o": ("openai", "gpt-4o")
        }
        
        selected_model = chat_request.model or "claude-sonnet"
        provider, model_name = model_config.get(selected_model, model_config["claude-sonnet"])
        
        # Load conversation history using SmartContext
        initial_messages = await smart_context.get_context(
            session_id=chat_request.session_id,
            db=db
        )
        
        # Create chat with history and call LLM with metrics
        chat = LlmChat(
            api_key=EMERGENT_LLM_KEY,
            session_id=chat_request.session_id,
            system_message=system_prompt,
            initial_messages=initial_messages
        ).with_model(provider, model_name)
        
        user_message = UserMessage(text=chat_request.message)
        async with observe_external_call(f"llm_{selected_model}"):
            response = await chat.send_message(user_message)
        
        # Save to DB with model info
        message_record = {
            "id": str(uuid.uuid4()),
            "session_id": chat_request.session_id,
            "user_message": chat_request.message,
            "ai_response": response,
            "model": selected_model,
            "timestamp": datetime.utcnow(),
            "user_data": chat_request.user_data
        }
        async with observe_db_operation('chat_messages', 'insert_one'):
            await db.chat_messages.insert_one(message_record)
        
        # Notify if contact provided
        if chat_request.user_data and chat_request.user_data.get('contact'):
            telegram_message = f"""
<b>üí¨ –õ–∏–¥ –∏–∑ AI-—á–∞—Ç–∞!</b>

<b>–ú–æ–¥–µ–ª—å:</b> {selected_model}
<b>–ò–º—è:</b> {chat_request.user_data.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
<b>–ö–æ–Ω—Ç–∞–∫—Ç:</b> {chat_request.user_data.get('contact')}
<b>–°–æ–æ–±—â–µ–Ω–∏–µ:</b> {chat_request.message}
"""
            try:
                await send_telegram_notification(telegram_message)
            except Exception as notify_error:
                logger.error("Telegram notification failed: %s", notify_error)
                sentry_sdk.capture_exception(notify_error)
        
        return ChatResponse(
            response=response,
            session_id=chat_request.session_id
        )
    except Exception as e:
        logger.error(f"AI chat error: {str(e)}")
        sentry_sdk.capture_exception(e)
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è")


# Include router
app.include_router(api_router)

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=[CLIENT_ORIGIN_URL],
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()
